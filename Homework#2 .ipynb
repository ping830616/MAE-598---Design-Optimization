{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ee8fac",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448246ca",
   "metadata": {},
   "source": [
    "Find a stationary point:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45b599b",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x_{1}, x_{2}) = 2x_{1}^2 - 4x_{1}x_{2} + 1.5x_{2}^2 + x_{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef2da54",
   "metadata": {},
   "source": [
    "$$\n",
    "{df \\over dx_{1}} = 4x_{1} - 4x_{2} = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba410408",
   "metadata": {},
   "source": [
    "$$\n",
    "{df \\over dx_{2}} = -4x_{1} + 3x_{2} +1 = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bc3eaf",
   "metadata": {},
   "source": [
    "the Hessian $H = \\begin{bmatrix} {d^2f \\over dx_{1}^2} & {d^2f \\over dx_{1}dx_{2}} \\\\ {d^2f \\over dx_{1}dx_{2}} & {d^2f \\over dx_{2}^2} \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ca80b0",
   "metadata": {},
   "source": [
    "$$\n",
    " \\Longrightarrow H = \\begin{bmatrix} 4 & -4 \\\\ -4 & 3 \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329e7c6c",
   "metadata": {},
   "source": [
    "Find $\\lambda:$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051b0c22",
   "metadata": {},
   "source": [
    "$$\n",
    "H-\\lambda I=0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6d6f86",
   "metadata": {},
   "source": [
    "$$\n",
    " \\Longrightarrow \\begin{bmatrix} 4-\\lambda & -4 \\\\ -4 & 3-\\lambda \\end{bmatrix} = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ccb793",
   "metadata": {},
   "source": [
    "$$\n",
    "(4-\\lambda)(3-\\lambda)-16=0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444eefe9",
   "metadata": {},
   "source": [
    "$$\n",
    "\\lambda = {7 \\pm \\sqrt{65} \\over 2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3bfd1b",
   "metadata": {},
   "source": [
    "Which shows that one eigenvalue is positive, and the other is negative, so the Hessian is indefinite, and the stationary point is a saddle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518d594b",
   "metadata": {},
   "source": [
    "Taylor's expansion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248ef1b1",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x_{1},x_{2}) - f(1,1) = f'(1,1)(x_{1}-1,x_{2}-1) + \\frac{1}{2}(x_{1}-1,x_{2}-1)^TH(x_{1}-1,x_{2}-1), \\;\\;\\;\\;\\;f'(1,1)=0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1626afe2",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x_{1},x_{2}) - f(1,1) = \\frac{1}{2}(x_{1}-1,x_{2}-1)^TH(x_{1}-1,x_{2}-1), \\;\\;\\;\\;dx_{1}=x_{1}-1; \\;dx_{2}=x_{2}-1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad978e87",
   "metadata": {},
   "source": [
    "$$\n",
    "= \\frac{1}{2}[dx_{1},dx_{2}]^T \\begin{bmatrix} 4 & -4 \\\\ -4 & 3 \\end{bmatrix} \\begin{bmatrix}dx_{1}\\\\dx_{2}\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff65868",
   "metadata": {},
   "source": [
    "$$\n",
    "= \\frac{1}{2}(4dx_{1}^2 - 8dx_{1}x_{2} + 3dx_{2}^2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08c4c5a",
   "metadata": {},
   "source": [
    "$$\n",
    "= \\frac{1}{2}(2dx_{1}-dx_{2})(2dx_{1}-3dx_{2})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347a60cd",
   "metadata": {},
   "source": [
    "Find the directions of downslopes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a872eee",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{1}{2}(2dx_{1}-dx_{2})(2dx_{1}-3dx_{2}) < 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbc8795",
   "metadata": {},
   "source": [
    "Therefore, the downslopes are: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f46dc42",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "$$\n",
    "(2dx_{1}-dx_{2})<0 \\; and \\;(2dx_{1}-3dx_{2}) > 0\n",
    "$$</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70774c5",
   "metadata": {},
   "source": [
    "$\\;\\;\\;\\;\\;\\;$or"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71e16a5",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "$$\n",
    "(2dx_{1}-dx_{2})>0 \\; and \\;(2dx_{1}-3dx_{2}) < 0\n",
    "$$</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27739617",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fa1482",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57990f1",
   "metadata": {},
   "source": [
    "Minimize the distance from the point (-1, 0, 1): "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555ab39e",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x_{1}, x_{2}, x_{3}) = (x_{1}+1)^2+x_{2}^2+(x_{3}-1)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfde77a8",
   "metadata": {},
   "source": [
    "Subject to:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea06483d",
   "metadata": {},
   "source": [
    "$$\n",
    "x_{1}+2x_{2}+3x_{3}=1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a3d333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a78d50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x):\n",
    "    x1 = x[0]\n",
    "    x2 = x[1]\n",
    "    x3 = x[2]\n",
    "    return (x1+1)**2+x2**2+(x3-1)**2\n",
    "def constraint1(x):\n",
    "    return x[0]+2*x[1]+3*x[2]-1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0923299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "x0 = [0, 0, 0]\n",
    "print(objective(x0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c3d9c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = (-100.0,100.0)\n",
    "bnds = (b,b,b)\n",
    "con1 = {'type': 'eq', 'fun': constraint1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "242cf659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 0.07142857142857148\n",
      "     jac: array([-0.14285713, -0.28571428, -0.42857141])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 21\n",
      "     nit: 5\n",
      "    njev: 5\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([-1.07142857, -0.14285715,  0.78571429])\n"
     ]
    }
   ],
   "source": [
    "print(minimize(objective,x0,method='SLSQP',bounds=bnds,constraints=con1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9ed932",
   "metadata": {},
   "source": [
    "Therefore, the solution is $x_{1}=-1.07142857,\\;x_{2}=-0.14285715,\\;x_{3}=0.78571429.$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fea83f",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "This is a convex problem since the unconstrained problem has the Hessian that is positive definite everywhere.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e79db84",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a637f29",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x_{2}, x_{3}) = (2-2x_{2}-3x_{3})^2+x_{2}^2+(x_{3}-1)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2b812c",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{df(x_{2}, x_{3})}{dx_{2}} = 10x_{2}+12x_{3}-8\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec34b70",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{df(x_{2}, x_{3})}{dx_{3}} = 12x_{2}+20x_{3}-14\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a06d61",
   "metadata": {},
   "source": [
    "### Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cba0cd74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 0]),\n",
       " array([0.0625  , 0.109375]),\n",
       " array([0.10986328, 0.19580078]),\n",
       " array([0.14542389, 0.26428223]),\n",
       " array([0.17178619, 0.31872964]),\n",
       " array([0.19098449, 0.36219818]),\n",
       " array([0.20460775, 0.39707492]),\n",
       " array([0.21389699, 0.42522498]),\n",
       " array([0.2257459 , 0.47098649]),\n",
       " array([0.22716314, 0.50022586]),\n",
       " array([0.22287655, 0.52006219]),\n",
       " array([0.20820431, 0.54894461]),\n",
       " array([0.124532  , 0.61427662]),\n",
       " array([0.08599204, 0.62803184]),\n",
       " array([0.03645422, 0.67896418]),\n",
       " array([0.02045071, 0.67844123]),\n",
       " array([-0.02277453,  0.70166208]),\n",
       " array([-0.03478701,  0.71666537]),\n",
       " array([-0.05054416,  0.72192391]),\n",
       " array([-0.06039699,  0.73242714]),\n",
       " array([-0.08354146,  0.74195478]),\n",
       " array([-0.0856678 ,  0.74706109]),\n",
       " array([-0.09917469,  0.75791006]),\n",
       " array([-0.10562305,  0.7599035 ]),\n",
       " array([-0.10953627,  0.76424141]),\n",
       " array([-0.11897805,  0.76794228]),\n",
       " array([-0.11977577,  0.77009513]),\n",
       " array([-0.12519875,  0.77452096]),\n",
       " array([-0.12784025,  0.77526882]),\n",
       " array([-0.12939171,  0.77706298]),\n",
       " array([-0.13131913,  0.77777804]),\n",
       " array([-0.13383727,  0.78031164]),\n",
       " array([-0.13462999,  0.78030584]),\n",
       " array([-0.13680127,  0.78148622]),\n",
       " array([-0.13741514,  0.78222939]),\n",
       " array([-0.13820272,  0.78250401]),\n",
       " array([-0.13870403,  0.78302604]),\n",
       " array([-0.13986305,  0.78351698]),\n",
       " array([-0.13997472,  0.78376751]),\n",
       " array([-0.14065759,  0.78431081]),\n",
       " array([-0.1409797 ,  0.78441549]),\n",
       " array([-0.14117901,  0.7846309 ]),\n",
       " array([-0.1416516 ,  0.78482215]),\n",
       " array([-0.14169378,  0.78492766]),\n",
       " array([-0.14196804,  0.78514919]),\n",
       " array([-0.14209991,  0.78518873]),\n",
       " array([-0.14217902,  0.78527775]),\n",
       " array([-0.14227544,  0.78531483]),\n",
       " array([-0.14240338,  0.78544092]),\n",
       " array([-0.14244267,  0.78544161])]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient descent\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import linregress\n",
    "\n",
    "\n",
    "obj = lambda x: (2 - 2*x[0] - 3*x[1])**2 + x[0]**2 + (x[1]-1)**2     # x[0] = x2; x[1] = x3\n",
    "def grad(x):\n",
    "     return np.array([10*x[0] + 12*x[1] - 8, 20*x[1] + 12*x[0] -14])\n",
    "    \n",
    "eps = 1e-3  # termination criterion \n",
    "\n",
    "x0= np.array([0,0])  # initial guess\n",
    "\n",
    "k = 0  # counter\n",
    "soln = [x0]  \n",
    "x = soln[k]  # initial guess\n",
    "error = np.linalg.norm(grad(x))  #  gradient norm\n",
    "a = 0.01  # a fixed step size \n",
    "\n",
    "# Inexact line search\n",
    "def line_search(x, d):  # d: search direction\n",
    "    a = 1.  # initialize step size\n",
    "    \n",
    "    def phi(a,x,d):\n",
    "        return obj(x)+a*0.8*np.dot(grad(x),d)\n",
    "\n",
    "    while phi(a,x,d)<obj(x+a*d): \n",
    "        a = 0.5*a\n",
    "        \n",
    "    return a\n",
    "\n",
    "while error >= eps:  \n",
    "    d = -grad(x)\n",
    "    \n",
    "    a = line_search(x, d)\n",
    "    \n",
    "    x = x+a*d\n",
    "    soln.append(x)\n",
    "    error = np.linalg.norm(grad(x))\n",
    "\n",
    "soln\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d3a0d357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [sol[0][0],sol[1][0],sol[2][0],sol[3][0],sol[4][0],sol[5][0],sol[6][0],sol[7][0],sol[8][0],\n",
    "     sol[9][0],sol[10][0],sol[11][0],sol[12][0],sol[13][0],sol[14][0],sol[15][0],sol[16][0],sol[17][0],\n",
    "     sol[18][0],sol[19][0],sol[20][0],sol[21][0],sol[22][0],sol[23][0],sol[24][0],sol[25][0],sol[26][0],\n",
    "     sol[27][0],sol[28][0],sol[29][0],sol[30][0],sol[31][0],sol[32][0],sol[33][0],sol[34][0],sol[35][0],\n",
    "     sol[36][0],sol[37][0],sol[38][0],sol[39][0],sol[40][0],sol[41][0],sol[42][0],sol[43][0],sol[44][0],\n",
    "     sol[45][0],sol[46][0],sol[47][0],sol[48][0],sol[49][0]]\n",
    "\n",
    "y = [sol[0][1],sol[1][1],sol[2][1],sol[3][1],sol[4][1],sol[5][1],sol[6][1],sol[7][1],sol[8][1],\n",
    "     sol[9][1],sol[10][1],sol[11][1],sol[12][1],sol[13][1],sol[14][1],sol[15][1],sol[16][1],sol[17][1],\n",
    "     sol[18][1],sol[19][1],sol[20][1],sol[21][1],sol[22][1],sol[23][1],sol[24][1],sol[25][1],sol[26][1],\n",
    "     sol[27][1],sol[28][1],sol[29][1],sol[30][1],sol[31][1],sol[32][1],sol[33][1],sol[34][1],sol[35][1],\n",
    "     sol[36][1],sol[37][1],sol[38][1],sol[39][1],sol[40][1],sol[41][1],sol[42][1],sol[43][1],sol[44][1],\n",
    "     sol[45][1],sol[46][1],sol[47][1],sol[48][1],sol[49][1]]\n",
    "\n",
    "plt.loglog(x, y, 'ro')\n",
    "plt.xlabel('log(x)', fontsize=13)\n",
    "plt.ylabel('log(y)', fontsize=13)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4f8e39",
   "metadata": {},
   "source": [
    "As for _Newton's Method_, I attached its coding file and plot seperately on my Github."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dc71df",
   "metadata": {},
   "source": [
    "The result of Newton's Method from Command Window in Matlab:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac41e3f3",
   "metadata": {},
   "source": [
    "***************************************************************\n",
    "Initial objective function value: 98\n",
    "\n",
    "Minimum finally reached! \n",
    "\n",
    "Number of iterations for convergence: 2\n",
    "\n",
    "The minimum: [-1.428571e-01,7.857143e-01]\n",
    "\n",
    "    Iterations       X_coordinate         Y_coordinate   \n",
    "    __________    __________________    _________________\n",
    "\n",
    "        1                          3                   -4\n",
    "        2         -0.142857142857143    0.785714285714286\n",
    "        \n",
    "***************************************************************\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad58043",
   "metadata": {},
   "source": [
    "It seems that Newton's Method can have a much faster convergence than Gradient Descent. Since Newton's Method can optimize much faster, it may have a much higher cost. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f89667",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c346b1",
   "metadata": {},
   "source": [
    "A hyperplane in $\\mathbb{R}^n$ can be expressed as: $\\;a^Tx=c\\;$ for $\\;x \\ni \\mathbb{R}^n$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa99a7e7",
   "metadata": {},
   "source": [
    "We want to show that these two points, $x_{1}$ and $x_{2}$ on the hyperplane in $\\mathbb{R}^n$ can be joined by a line segment between them:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67422af9",
   "metadata": {},
   "source": [
    "$$\n",
    "x = \\lambda x_{1}+(1-\\lambda)x_{2}, \\;\\;\\; \\lambda \\longleftarrow [0, 1]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd93610",
   "metadata": {},
   "source": [
    "$$\n",
    "a^Tx=a^T(\\lambda x_{1}+(1-\\lambda)x_{2})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1e5aed",
   "metadata": {},
   "source": [
    "$$\n",
    "a^Tx=\\lambda a^Tx_{1}+(1-\\lambda)a^Tx_{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceefbf56",
   "metadata": {},
   "source": [
    "$$\n",
    "a^Tx=\\lambda c+(1-\\lambda)c\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37271c3",
   "metadata": {},
   "source": [
    "$$\n",
    "a^Tx=(\\lambda+1-\\lambda) c\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e79209",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "$$\n",
    "a^Tx=c\n",
    "$$\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b95bda9",
   "metadata": {},
   "source": [
    "Therefore, it proves that a hyperplane is indeed a convex set since x lies on the hyperplane."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b87e6a",
   "metadata": {},
   "source": [
    "## Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81364ddd",
   "metadata": {},
   "source": [
    "The problem:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811bb55a",
   "metadata": {},
   "source": [
    "$$\n",
    "\\min \\limits _{p} \\; \\sum \\limits _{k=1}^{m} (a_{k}^Tp-I_{t})^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb8d54f",
   "metadata": {},
   "source": [
    "The Hessian of the function:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4782ca64",
   "metadata": {},
   "source": [
    "$$\n",
    "H = 2 \\sum \\limits _{k=1}^{m} a_{k}a_{k}^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2894a02b",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806e7658",
   "metadata": {},
   "source": [
    "The problem is convex since the function is subject to the simple bound constraints, $0 \\leq p_{i} \\leq p_{max}$, and $H \\geq$ 0 (p.s.d)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7affdf54",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee7e0d9",
   "metadata": {},
   "source": [
    "The constraint added: $\\;\\sum \\limits _{k=1}^{n} p_{i} \\leq p* $, $\\;n=10$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae9d40c",
   "metadata": {},
   "source": [
    "The problem will have a unique solution since the problem having a convex feasible domain does not change after adding this linear constraint in $p$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e55ce88",
   "metadata": {},
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cae8e6",
   "metadata": {},
   "source": [
    "The constraint added: $\\;\\sum \\limits _{k=1}^{10} true(p_{i} > 0) \\leq 10 \\;\\;$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e686c48",
   "metadata": {},
   "source": [
    "If $false$, the problem would be non-convex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75b1fde",
   "metadata": {},
   "source": [
    "In this case, n = 10. The problem has a unique solution when these 10 instances in total occur:<br>  $(p_{1},p_{2},p_{3},p_{4},p_{5},p_{6},p_{7},p_{8},p_{9},p_{10}) = (10,0,0,0,0,0,0,0,0,0)$,<br>  $(p_{1},p_{2},p_{3},p_{4},p_{5},p_{6},p_{7},p_{8},p_{9},p_{10}) = (0,10,0,0,0,0,0,0,0,0)$  $...$ and <br> $(p_{1},p_{2},p_{3},p_{4},p_{5},p_{6},p_{7},p_{8},p_{9},p_{10}) = (0,0,0,0,0,0,0,0,0,10)$, meaning that one lamp is on and the other off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3dcdda",
   "metadata": {},
   "source": [
    "## Problem 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9440cacb",
   "metadata": {},
   "source": [
    "$$\n",
    "c^*(y)= \\max \\limits _{x}[xy-c(x)]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccac332",
   "metadata": {},
   "source": [
    "$$\n",
    "= \\max \\limits _{x}[x_{1}y-c(x_{1}), x_{2}y-c(x_{2}), ..., x_{n}y-c(x_{n})]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013c58e0",
   "metadata": {},
   "source": [
    "When $c^*(y)$ is derivative twice with respect to y, then:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73091215",
   "metadata": {},
   "source": [
    "$$\n",
    "c^*(y) = \\max \\limits _{x}[0, 0, ..., 0]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e6edc9",
   "metadata": {},
   "source": [
    "Therefore, the Hessian is equal to zero and positive semi-definite, showing that $c^*(y)$ is a convex function with respect to y."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
